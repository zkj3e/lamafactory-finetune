# ⚙️ 什么是超参数（Hyperparameter）

## 🧠 一、定义

**超参数（Hyperparameter）** 是指 **在训练模型之前就需要手动设置的参数**，它**不会在训练过程中自动学习得到**，而是影响模型训练过程和最终性能的“外部控制变量”。

简而言之：
> 模型在训练中自己学的是 **参数（parameter）**，  
> 而你提前告诉模型“怎么学”的，就是 **超参数（hyperparameter）**。

---

## 🧩 二、参数 vs 超参数

| 类别 | 例子 | 谁决定的？ | 是否在训练中学习？ | 存储位置 |
|------|------|-------------|--------------------|------------|
| **参数（Parameter）** | 神经网络的权重、偏置 | 模型自动学习 | ✅ 是 | 模型内部 |
| **超参数（Hyperparameter）** | 学习率、批次大小、层数、隐藏单元数 | 人工设定或自动调参 | 🚫 否 | 模型外部（配置文件/命令行） |

---

## 🧮 三、常见的超参数举例

| 类型 | 名称 | 说明 |
|------|------|------|
| **优化相关** | 学习率（learning rate） | 决定每次参数更新的步长 |
|  | batch size | 每次训练中使用的数据样本数 |
|  | optimizer | 优化算法类型（如 Adam、SGD、RMSProp） |
| **模型结构相关** | 隐藏层数量（num_layers） | 网络的层数 |
|  | 每层神经元数（hidden_size） | 每层的宽度 |
|  | dropout 比例 | 随机丢弃神经元比例，用于防止过拟合 |
| **正则化相关** | weight decay | 防止权重过大导致过拟合 |
| **训练策略相关** | epoch 数 | 整个训练集被遍历的次数 |
|  | learning rate schedule | 学习率随时间的变化策略 |

---

## 🔬 四、为什么需要调超参数？

不同的超参数组合会导致模型：
- 收敛更快或更慢；
- 训练集表现很好但测试集很差（过拟合）；
- 无法学到规律（欠拟合）。

因此我们需要通过 **验证集（val set）** 来测试不同的超参数组合，从而找到最优配置。

---

## 🤖 五、常见的超参数搜索方法

| 方法 | 说明 |
|------|------|
| **Grid Search** | 穷举法，尝试所有组合（计算量大） |
| **Random Search** | 随机采样部分组合（高效） |
| **Bayesian Optimization** | 通过概率模型智能选择下一个尝试点 |
| **Hyperband / Optuna / Ray T**
